{
  
    
        "post0": {
            "title": "Quick prototyping with fastai2 (Car classifier example)",
            "content": "What we will do ? . We will build a simple car classfier, you basicly give it an image of a car (interior or exterior) and the model will &#39;guess&#39; what brand it is and if it is the interior or exterior of it. Okay, let&#39;s do this. . Before we start . I will not go into every detail of the code, so prior knowledge of python is required. Also make sure that you are using a GPU (for colab just click Runtime -&gt; Change runtime type -&gt; GPU). That said we will first start by importing the tools that we will need to do the job. . !pip install -Uqq fastbook # import fastbook # fastbook.setup_book() from fastbook import * from fastai.vision.widgets import * . |████████████████████████████████| 727kB 8.8MB/s |████████████████████████████████| 51kB 7.7MB/s |████████████████████████████████| 51kB 6.8MB/s |████████████████████████████████| 1.0MB 24.5MB/s |████████████████████████████████| 194kB 57.2MB/s |████████████████████████████████| 40kB 6.3MB/s |████████████████████████████████| 92kB 12.3MB/s |████████████████████████████████| 51kB 8.4MB/s |████████████████████████████████| 61kB 9.9MB/s |████████████████████████████████| 51kB 8.3MB/s |████████████████████████████████| 2.6MB 58.3MB/s . 1. Get the data . To train a model, we will need data that it uses to learn from (it&#39;s like a student learning from a book, where the student is the model and the book is the data). For that we will download our car images using the Bing Api Key, to get one i will refer to this great post by Ivoline Ngong on the fastai forums: Get bing api key. Okay, now that we got our key we will use it to download the images in this case, we will download Audi/ BMW/ Mercedes (interior/exterior) images and put them in different folders accroding to their category (we will call &#39;categories&#39; labels from now on, this is the jargon used in deep learning) . key = &#39;d4a51bcea8bd4a94b7d2d467b8b5d987&#39; path = Path(&#39;/content/images&#39;) brands = [&#39;bmw&#39;, &#39;mercedes&#39;, &#39;audi&#39;] perspective = [&#39;interior&#39;, &#39;exterior&#39;] result = itertools.product(brands, perspective) if not path.exists(): path.mkdir() for b, p in result: dest = Path(path/f&#39;{b}_{p}&#39;) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{b} {p}&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . We then check if there are any corrupted files in the mix, we use verify_images for that (which is provided by fastai), and we obviously unlink (delete) them, so we don&#39;t encounter errors further down the road. . You can notice that we use an intresting method which is provided by fastai, get_images_files, which is used as the name suggests to search for images (with different extensions) in a given path (input), this is done recursively by default (searches in all sub-directories of the path given) and returns a list of paths of those images. . fns = get_image_files(path) failed = verify_images(fns) failed.map(Path.unlink) . (#5) [None,None,None,None,None] . 2. Clean the data . Now comes the &quot; NO, GOD PLEASE NO &quot; moment, but will try to make it a bit more &quot;fun&quot;. . The intuitive approach will be to do data cleaning before we train our model, but what we will do instead is train a quick and simple model to help us clean the data. . Don&#39;t worry about the code for, we&#39;ll explain how train a model later. . db = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.1, seed=42), get_y=parent_label, item_tfms=Resize(244)) dls = db.dataloaders(path) learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . epoch train_loss valid_loss error_rate time . 0 | 2.345028 | 1.059248 | 0.413793 | 00:31 | . epoch train_loss valid_loss error_rate time . 0 | 1.212386 | 1.005042 | 0.356322 | 00:31 | . 1 | 1.053597 | 1.014616 | 0.298851 | 00:32 | . 2 | 0.831190 | 0.910729 | 0.275862 | 00:32 | . 3 | 0.692817 | 0.914627 | 0.287356 | 00:31 | . If we plot our top losses (the images for which the model got the wrong guess), we see that he was not that wrong after all. I mean, taking the first image it looks like a bmw exterior to me. . Well this is due to downloading images from bing, when you do a search for images (in any search engine) you will get the desired images that you searched for but sometimes, you&#39;ll get some &quot; undesired &quot; ones as well. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_top_losses(2, nrows=2) . So what do we do now ? Good question, we will use a tool provided by fastai to clean our data, which is called ImageClassifierCleaner. And it provides us with a nice GUI interface that we can interact with to delete/ keep (by default) /or modify the label of the images in the dataset. . The ImageClassifierCleaner does not allow us to delete or modify the labels directly but rather gives a list of the paths of the different images that we selected. . You will have to iterate this process untill you have cleaned your dataset (e.g. Re-train -&gt; plot top losses -&gt; clean) . cleaner = ImageClassifierCleaner(learn) cleaner . In this example, we will change the labels (category) from bmw interior to bmw exterior. . for idx,cat in cleaner.change(): cleaner.fns[idx].rename(path/cat/f&#39;(1){cleaner.fns[idx].name}&#39;) . 3. Training . Before training our model we will need to turn our downloaded data into a DataLoaders object (which is just an object containing our train and validation set, e.g. the images used for training and the images used to test how well our model performs), we need to tell fastai at least four things: . What kinds of data we are working with: blocks=(ImageBlock, CategoryBlock), we are dealing with images and we want categories as the output. | How to get the list of items get_items=get_image_files (remember this the method we described earlier) | How to label these items . get_y=parent_label, this means we label them according to the folder they&#39;re in. | How to create the validation set splitter=RandomSplitter(valid_pct=0.1, seed=42), we take 10% of our images and use them to test how good our model performs, and set the seed so we always have the same split. | . We also are going to be using a technique called Data Augmentation, which is just a set of standard transformations applied to our images (rotation, contrast, brightness, ..., all are contained in the aug_transforms method), this is usually done to increase the size of our dataset, when you have a small one (not a lot of images) like our case. . item_tfms=RandomResizedCrop(244, min_scale=0.5), batch_tfms=aug_transforms() . Now the difference between item_tfms and batch_tfms, is just that one is applied one item at a time, the other is applied to a batch of images at a time (this is where the GPU comes in handy, beacause it can do multiple tasks in parallel, the CPU does this sequencially). . Note that we also resize all of our images into 244x244 format, so all our images are of the same size (but you can choose any size you want). . db = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.1, seed=42), get_y=parent_label, item_tfms=Resize(244)) dls = db.dataloaders(path) . Now, to train our model we will use a technique called transfor learning, which basicly means to use an already pre-trained model (which was trained for some task) for a different task that we are intrested in (classifiying cars). . We will call the method cnn_learner for this purpose, we put our Dataloaders object as the first parameter, the architecture as the second (which is the &quot;mathematical template of our function&quot; in this case Resnet, 34 just means the number of layers), and last argument is the metric, which the thing that we use as humans to evaluate how good the model performs (in this case error_rate, which is the ratio of number of misclassified images / total number of images). . Finally, we use the method fine_tune, which will do two things : . Do one epoch (one pass through the dataset) to ajust the parts of the model to get the new random head working (the head is the last layer, we change it because we are using our model for a different task than it was used before). | Use the number of epochs requested (in this case 10) to fit (train) the entire model, and updating the last layers especially the head faster then the earlier ones (because using an already pre-trained model, the first layers already &#39;detect&#39; basic faatures like straight lines, and we are interested in updating the last ones because they are responsible of sophisticated features like detecting wheels, car doors, ...). | . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(10) . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth . . epoch train_loss valid_loss error_rate time . 0 | 2.339309 | 1.290998 | 0.505747 | 00:32 | . epoch train_loss valid_loss error_rate time . 0 | 1.294172 | 0.868396 | 0.321839 | 00:32 | . 1 | 1.035632 | 0.653016 | 0.241379 | 00:33 | . 2 | 0.823092 | 0.467765 | 0.137931 | 00:33 | . 3 | 0.627784 | 0.434415 | 0.137931 | 00:32 | . 4 | 0.491646 | 0.489917 | 0.160920 | 00:32 | . 5 | 0.384105 | 0.437487 | 0.137931 | 00:32 | . 6 | 0.303227 | 0.383987 | 0.103448 | 00:32 | . 7 | 0.244072 | 0.372062 | 0.080460 | 00:33 | . 8 | 0.199574 | 0.364913 | 0.080460 | 00:33 | . 9 | 0.167494 | 0.368371 | 0.080460 | 00:33 | . After training our model, we can plot the confusion matrix, which will give us better insight of how our model is doing for the different labels. . You want to have dark blues in the diagonal, this means that your model is classifying the different images correctly. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Inference . Now, to really test our model, we will test it using images that he has not seen before, or else it would be conidered cheating. It&#39;s like a student passing an exam he will not be given questions that he already knows the answers to but rather will probably get questions that he had not seen before, but in the context of what he studied. . When using a model to get predictions, we call it Inference. . For that we&#39;ll be using the predict method, that just takes the image as the input. And returns three things, the prediction (what car it thinks it is), the &quot;posistion&quot; of the label in the vocab, and the probability for each label. . img = PILImage.create(&#39;/content/bmw_exterior_2.jpg&#39;) img.to_thumb(244) . predict, position, proba = learn.predict(img) predict, position, proba . (&#39;bmw_exterior&#39;, tensor(2), tensor([9.8757e-08, 2.9618e-10, 1.0000e+00, 1.8380e-09, 4.8084e-06, 4.3692e-08])) . Our model thinks it&#39;s a BMW exterior with 100% certainty, PERFECT !!! . To export our model for later use, or integrate in an app, or whatever have you, we just use the export method. Which will export the model as a pickle file, with all the learned weights and how it should load the data (so you just import, plug in the image and you get the results). . We use load_learner to load the model. . learn.export() .",
            "url": "https://igrek-code.github.io/blog/2020/10/28/fastai-car-classifier.html",
            "relUrl": "/2020/10/28/fastai-car-classifier.html",
            "date": " • Oct 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Drive Train Approach",
            "content": "Drivetrain approach with example (minimizing spread of COVID-19 across students of a department) . : . Drivetrain approach with example (minimizing spread of COVID-19 across students of a department) What is the Drivetrain approach ? | Ok, but what does it consist of ? | Example | Reference | | What is the Drivetrain approach ? . It is basicly a process to design data products, to ensure that your modeling work is useful in practise. It was introduced in 2012 by Jeremy, along with Margit Zwemer and Mike Loukides. You can find out more about it here: Designing good data products . Ok, but what does it consist of ? . Well, now that we saw what it was usefull for, and where it came from, let’s see the four steps that compose it 1. . . We need to define the objective (the end goal) | Next we need to identify the levers (what can we control) | After that collect relevent data | Finally train our model | Example . No good explanation is made without a concrete example, so let’s do that. . As a graduate student i will be attending classes, with other students, but as of today we are living in the COVID-19 crysis. And i don’t want to catch it. . Let’s say i’am a director of the computer science department. And i want to minimize the spread of COVID-19 across students of my department (this is the objective). . One of the things i can controll, is to make sure everyone is wearing a face mask, by installing for example cameras across the department entries that would detect if you are wearing a mask or not and would let you or not enter by say opening the door or locking it (this is the lever). . Now to make such a system, i’ll need to train a model for image recognition, so i’ll collect data which will consist of people wearing masks and others not (that’s the data phase). . Finally come the ‘fun’ part where you actually train your model and get to see it in action. . Reference . This blog post was highly influenced by the book Deep Learning for Coders with fastai &amp; PyTorch, in fact i’am writing this blog as part of the homework. If there is any problem of copyright regarding the use of the picture or anything else please let me know. &#8617; . |",
            "url": "https://igrek-code.github.io/blog/2020/10/26/drive-train-approach.html",
            "relUrl": "/2020/10/26/drive-train-approach.html",
            "date": " • Oct 26, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "",
          "url": "https://igrek-code.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://igrek-code.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}