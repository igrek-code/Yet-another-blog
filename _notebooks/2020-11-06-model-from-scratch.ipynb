{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_SCRATCH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7btCBh9rSTQ6"
      },
      "source": [
        "# Create and train a model from scratch !\n",
        "\n",
        "- toc: true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUiaj-Dq2Fdk"
      },
      "source": [
        "## What will we do ?\n",
        "We will create a *linear* model then a *neural network* from scratch to do *binary classification*, train them using *gradient descent* and finally see how current libraries sipmlify these things for us and we'll create our own class that mimicks the tools provided by these libraries.\n",
        "\n",
        "> If you never used *Pytorch* before, i would refer you to my other post [Start simple, start with a baseline !](https://igrek-code.github.io/blog/2020/11/01/start-simple-start-with-a-baseline.html), which gives a more gentle introduction to the tools needed here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Gkz_py2CdZ",
        "outputId": "60faa817-ae30-450a-d09d-43ce379786da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 4.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 41.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 37.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U5OYUIq5-LA"
      },
      "source": [
        "## Getting and preparing the data (you can skip this part)\n",
        "\n",
        "We'll be using the *MNIST_SAMPLE* dataset provided by *fastai*, which contains images of 3's and 7's.\n",
        "\n",
        "We start by downloading the data, opening the images, turning them into tensors and stacking them into a rank-3 tensors (matrix) for each label (train/valid) separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15X-4_4w2OsD",
        "outputId": "6c4b39d4-ae55-407b-a568-08d4ff590557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "three_train = torch.stack([tensor(Image.open(o)).float()/255 for o in (path/'train'/'3').ls()])\n",
        "seven_train = torch.stack([tensor(Image.open(o)).float()/255 for o in (path/'train'/'7').ls()])\n",
        "seven_valid = torch.stack([tensor(Image.open(o)).float()/255 for o in (path/'valid'/'7').ls()])\n",
        "three_valid = torch.stack([tensor(Image.open(o)).float()/255 for o in (path/'valid'/'3').ls()])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdR-Dkae6rNQ"
      },
      "source": [
        "Then, we'll concatenate 3/7 tensors obtained (train/ valid seperately) into one single tensor and flatten the images out by reshaping the tensors. \n",
        "\n",
        "For our independant variables we'll create the corresponding tensor, with 1 indicating a 3 and 0 indicating a 7. Add a dimension, to not have problems further down the road (due to broadcasting)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycOsyiZ42Wjv",
        "outputId": "8db2b03b-a462-4de8-baca-aededb53504e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_x = torch.cat([three_train, seven_train]).view(-1, 28*28)\n",
        "train_y = tensor([1] * len(three_train) + [0] * len(seven_train)).unsqueeze(1)\n",
        "train_x.shape, train_y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SahdWdkl2u9c",
        "outputId": "ddf0aaa5-87e5-4755-80de-acd7e85bc883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_x = torch.cat([three_valid, seven_valid]).view(-1, 28*28)\n",
        "valid_y = tensor([1] * len(three_valid) + [0] * len(seven_valid)).unsqueeze(1)\n",
        "valid_x.shape, valid_y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2038, 784]), torch.Size([2038, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69qJJgq9-KGx"
      },
      "source": [
        "Create our **dataset** (for PyTorch it is a list of tuples containing our dependant/ independant variables).\n",
        "\n",
        "Then create our **dataloader**, which is obtained by shuffling the **dataset**, and creating batches of size 256.\n",
        "\n",
        "And wrap that in a *Dataloaders* object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy5PGIGV2qU0"
      },
      "source": [
        "dset = list(zip(train_x, train_y))\n",
        "dl = DataLoader(dset, batch_size=256, shuffle=True)\n",
        "dset_valid = list(zip(valid_x, valid_y))\n",
        "dl_valid = DataLoader(dset_valid, batch_size=256, shuffle=True)\n",
        "dls = DataLoaders(dl, dl_valid)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIGeOOtB_GQz"
      },
      "source": [
        "## Create and train the model\n",
        "\n",
        "### 1. From scratch approach\n",
        "\n",
        "Okay, now that we've done the kinda \"boring\" part, let's dive into our subject of interest.\n",
        "\n",
        "To assess how good our model is (human consumption), we'll need to define a *metric*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwKBoah325XZ"
      },
      "source": [
        "def batch_accuracy(predictions, targets):\n",
        "    return ((predictions > 0) == targets).float().mean()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSFmAyT__lyH"
      },
      "source": [
        "Now we also need to define a loss function, that we will optimize using SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSbf9-1H3OH2"
      },
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "  result = predictions.sigmoid()\n",
        "  return torch.where(targets == 1, 1 - result , result).mean()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxVZjWmbAGdi"
      },
      "source": [
        "Where's the model at ? No worries, he's just here waiting for you !\n",
        "\n",
        "> In python \"**@**\" refers to matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WWL6_KoAOp5"
      },
      "source": [
        "def linear(xb): return xb @ w + b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el22lcgJAVgY"
      },
      "source": [
        "Something to randomly initialize the parameters with. And initialize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDT3nTsWAb31"
      },
      "source": [
        "def init_params(*size): return (torch.randn(size)).requires_grad_()\n",
        "w, b = init_params(28*28, 1), init_params(1) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyDBMFYBBTnL"
      },
      "source": [
        "We need a training loop that corresponds to the graph below. So let's do just that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKz3xxCuA9L4",
        "outputId": "d9a3a8c8-5da9-4df6-9549-da258f36522e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fe5c23a0828>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQK5_ISg3IC0",
        "outputId": "2d49e45d-bdca-4d35-a15e-7339165dff77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 5\n",
        "# setting the learning rate\n",
        "lr = 1\n",
        "# Training loop\n",
        "for i in range(epochs):\n",
        "  for xb, yb in dls[0]:\n",
        "    # Predict\n",
        "    result = linear(xb)\n",
        "    # Calculate the loss\n",
        "    loss = mnist_loss(result, yb)\n",
        "    # Calculate the gradient\n",
        "    loss.backward()\n",
        "    # Take a step\n",
        "    w.data -= w.grad * lr\n",
        "    b.data -= b.grad * lr\n",
        "\n",
        "    # Set the gradient to zero, s the next time we calculate it, it doesn't accumulate\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  # Show the batch accuracy for each epoch\n",
        "  print(tensor([batch_accuracy(linear(xb), yb) for xb, yb in dls[1]]).mean().item(), end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9121212959289551 0.9434308409690857 0.9494490027427673 0.9557371139526367 0.9602308869361877 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fCEGsvsDucZ"
      },
      "source": [
        "Now let's scale up a bit, and go for the neural net.\n",
        "Which will consist of two linear layers (first and last) and one non-linearity between them (Which in this case is the rectified linear unit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq7Yv01lDzRK"
      },
      "source": [
        "def simple_net(xb):\n",
        "  result1 = xb @ w1 + b1 \n",
        "  result2 = F.relu(result1)\n",
        "  return result2 @ w2 + b2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcIXKMk0EYFp"
      },
      "source": [
        "w1, b1 = init_params(28*28, 30), init_params(30)\n",
        "w2, b2 = init_params(30, 1), init_params(1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ABpOE9xJNP_"
      },
      "source": [
        "We'll be using the same training loop, but since it's a more \"complex\" model, we'll lower the learning rate and train for more epochs. So we'll just show the accuracy for the last epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdR4ifpWIonA",
        "outputId": "72ae3c3f-85f8-4443-e25a-15a2d304cf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 40\n",
        "# setting the learning rate\n",
        "lr = 0.1\n",
        "# Training loop\n",
        "for i in range(epochs):\n",
        "  for xb, yb in dls[0]:\n",
        "    # Predict\n",
        "    result = simple_net(xb)\n",
        "    # Calculate the loss\n",
        "    loss = mnist_loss(result, yb)\n",
        "    # Calculate the gradient\n",
        "    loss.backward()\n",
        "    # Take a step\n",
        "    w1.data -= w1.grad * lr\n",
        "    b1.data -= b1.grad * lr\n",
        "    w2.data -= w2.grad * lr\n",
        "    b2.data -= b2.grad * lr\n",
        "\n",
        "    # Set the gradient to zero, s the next time we calculate it, it doesn't accumulate\n",
        "    w1.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    b2.grad.zero_()\n",
        "\n",
        "# Show the batch accuracy for the last epoch\n",
        "print(tensor([batch_accuracy(simple_net(xb), yb) for xb, yb in dls[1]]).mean().item(), end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.953414797782898 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M93sNajBKkPr"
      },
      "source": [
        "### 2. Using existing tools\n",
        "\n",
        "Okay, but all of what we've done so far can already be implemented using *fastai2* and *PyTorch* using just these lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh8A3tE3KzCI"
      },
      "source": [
        "# Create the model, same neural network as above (it will also initialize the params)\n",
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 1)\n",
        ")\n",
        "\n",
        "# Create the Learner object\n",
        "\n",
        "learn = Learner(dls, simple_net, loss_func=mnist_loss, opt_func=SGD, metrics=batch_accuracy)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "learn.fit(40, lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7zWSLG9MGQs"
      },
      "source": [
        "As you can see we create a **Learner** object, it's a class that handles all the training process for you, you just give it five things:\n",
        "\n",
        "- Your dataloaders object.\n",
        "- The model.\n",
        "- The loss function to optimize.\n",
        "- The optimization function.\n",
        "- The metrics to be displayed (Optionnal).\n",
        "\n",
        "> The optimization function (Optimizer) in *PyTorch* is a function that handles the gradient step for you, e.g. updating the params and setting the gradient to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnySwxQoMvxG"
      },
      "source": [
        "# Create the optimizer\n",
        "\n",
        "opt = SGD(simple_net.parameters(), 0.1) # we give it the params and learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp5t0qgmM3_B"
      },
      "source": [
        "Let's try to mimik this by creating our own **Learner** class from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM3Ba5l_3UDY"
      },
      "source": [
        "class MyLearner:\n",
        "\n",
        "  # Initializing the learner\n",
        "\n",
        "  def __init__(self, dls, model, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy): \n",
        "    self.dls = dls \n",
        "    self.model = model \n",
        "    self.opt_func = opt_func \n",
        "    self.loss_func = loss_func \n",
        "    self.metrics = metrics\n",
        "\n",
        "    # We store the metric values in a list (to plot them for example)\n",
        "    self.metric_values = []\n",
        "\n",
        "  # Method for training our model\n",
        "\n",
        "  def fit(self, epochs, lr=1):\n",
        "\n",
        "    # Create the optimizer\n",
        "    opt = self.opt_func(self.model.parameters(), lr)\n",
        "\n",
        "    # Training loop (same as before)\n",
        "    for i in range(epochs):\n",
        "        for xb, yb in self.dls[0]:\n",
        "          result = self.model(xb)\n",
        "          loss = self.loss_func(result, yb)\n",
        "          loss.backward()\n",
        "\n",
        "          # We update the weights using our optimizer\n",
        "          opt.step()\n",
        "\n",
        "          # Setting the gradient to zero using the same optimizer\n",
        "          opt.zero_grad()\n",
        "\n",
        "        # Calculate the metric value, store it and print it for each epoch  \n",
        "        b_accuracy = tensor([self.metrics(self.model(xb), yb) for xb, yb in self.dls[1]]).mean().item()\n",
        "        self.metric_values.append(b_accuracy)\n",
        "        print(round(b_accuracy, 4), end=' ')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV5TR3XPPjVp"
      },
      "source": [
        "Let's try it for a simple linear model. IT WORKS !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfHytptUPiuM",
        "outputId": "639c891e-39fb-424b-d32b-8044a7e1ad6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Create a MyLearner object\n",
        "my_learner = MyLearner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "\n",
        "# Train it\n",
        "my_learner.fit(20)\n",
        "\n",
        "# Plot the metric values with each epoch\n",
        "plt.plot(my_learner.metric_values);"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9706 0.9749 0.977 0.9779 0.9784 0.9789 0.9794 0.9808 0.9793 0.9798 0.9803 0.9803 0.9813 0.9808 0.9813 0.9814 0.9823 0.9829 0.9823 0.9824 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}